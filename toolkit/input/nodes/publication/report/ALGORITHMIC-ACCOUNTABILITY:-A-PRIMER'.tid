created:1578297321088
modified:1578297321088
title:ALGORITHMIC ACCOUNTABILITY: A PRIMER'
type:text/vnd.tiddlywiki
audience:
authors.editors:[[robyn caplan]] [[joan donovan]] [[lauren hanson]] [[and jeanna matthews]]
date:
digital.harms.addressed:
element.type:publication
github.profile:
input.source:me2b
jurisdiction:
license:
name:ALGORITHMIC ACCOUNTABILITY: A PRIMER'
publication.type:[[report]]
purpose:
sector:
sponsoring.org:
tags:
tech.focus:
tmap.edges:{}
tmap.id:4aa90686-e81c-45f7-903b-da24845ebd8e
url:https://datasociety.net/output/algorithmic-accountability-a-primer/
version.or.edition:
volume.frequency:
working.group:

There are few consumer or civil rights protections that limit the types of data used to build data profiles or that require the auditing of algorithmic decision-making.

Big decisions about people’s lives are increasingly made by software systems and algorithms. Sorting résumés for job applications, allocating social services, and deciding who sees advertisements for open positions, housing, and products are just a few of the ways in which these software systems shape our lives.

While algorithmic decision-making can offer benefits in terms of speed, efficiency, and even fairness, bias is routinely introduced into software systems in many ways, including the use of biased training data.
